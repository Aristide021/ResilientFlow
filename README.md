# ResilientFlow ğŸŒªï¸

**AI-Powered Disaster Relief Coordination System**

ResilientFlow is a swarm of ADK based agents that ingest multi-modal disaster data in real time, assess damage, optimize resource allocation, and broadcast multilingual public alerts â€” all running serverlessly on Google Cloud.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Cloud Run](https://img.shields.io/badge/Google%20Cloud-Run-blue)](https://cloud.google.com/run)
[![BigQuery](https://img.shields.io/badge/Google%20Cloud-BigQuery-blue)](https://cloud.google.com/bigquery)

## ğŸ¯ Vision

**From fragmented, slow disaster response to coordinated, intelligent relief in under 2 minutes.**

### Key Metrics
- **< 2 min** from first data receipt to resource-allocation plan
- **< 30 s** alert-push latency  
- **â‰¥ 90%** accuracy of impact heat-map versus human analyst ground-truth

## ğŸ—ï¸ Architecture

```
ğŸ“¡ Data Ingress â†’ ğŸ¤– Agent Swarm â†’ ğŸ“Š Analysis & Alerts â†’ ğŸš Resource Deployment
```

### Agent Swarm

| Agent | Role | Technology |
|-------|------|------------|
| **Data Aggregator** | Satellite imagery processing | Vertex AI Vision, Cloud Functions |
| **Impact Assessor** | Spatial analysis & heat-maps | BigQuery GIS, ML clustering |
| **Resource Allocator** | Logistics optimization | Google OR-Tools, Cloud Run Jobs |
| **Comms Coordinator** | Multilingual alerts | Translate API, FCM, SMS |
| **Report Synthesizer** | PDF situation reports | ReportLab, Cloud Storage |

### Data Flow

```mermaid
graph TD
    A[Satellite Images] -->|Cloud Storage Trigger| B[Data Aggregator]
    C[IoT Sensors] -->|Pub/Sub| D[Stream Aggregator]
    E[Social Media] -->|Pub/Sub| D
    
    B --> F[BigQuery GIS]
    D --> F
    F --> G[Impact Assessor]
    G --> H[Resource Allocator]
    G --> I[Comms Coordinator]
    H --> I
    G --> J[Report Synthesizer]
    H --> J
    
    I --> K[FCM Push Notifications]
    I --> L[SMS Alerts]
    J --> M[PDF Reports]
    J --> N[GeoJSON Data]
```

## ğŸš€ Quick Start

### Prerequisites

- Google Cloud Project with billing enabled
- `gcloud` CLI authenticated
- Terraform >= 1.0
- Docker
- Python 3.11+

### Deploy in 3 Commands

```bash
# 1. Clone and setup
git clone https://github.com/your-org/resilientflow.git
cd resilientflow

# 2. Deploy infrastructure and agents
export GOOGLE_CLOUD_PROJECT="your-project-id"
./scripts/bootstrap.sh

# 3. Run complete demo (< 3 minutes!)
python3 scripts/quick_demo.py $GOOGLE_CLOUD_PROJECT
```

### ğŸ¯ Roadmap Status: **AHEAD OF SCHEDULE!**

| Day | Status | Milestone | 
|-----|--------|-----------|
| **D-6** | âœ… **COMPLETE** | Project skeleton online, 5 agents deployed |
| **D-5** | âœ… **COMPLETE** | Pub/Sub wiring + visualizer ready |
| **D-4** | ğŸ”¨ **IN PROGRESS** | Vision pipeline + Impact Assessor MVP |
| **D-3** | âœ… **COMPLETE** | Resource Allocator + Firestore state |
| **D-2** | âœ… **COMPLETE** | Comms + Report Synthesizer |
| **D-1** | ğŸ¯ **READY** | Polish & failure drills |

### âš¡ **Next Actions** (15 minutes each):

```bash
# 1. Deploy the visualizer
./scripts/deploy_visualizer.sh

# 2. Setup Vertex AI (mock for demo)
python3 scripts/vertex_ai_setup.py $GOOGLE_CLOUD_PROJECT

# 3. Test complete pipeline
python3 scripts/quick_demo.py $GOOGLE_CLOUD_PROJECT
```

## ğŸ“ Project Structure

```
resilientflow/
â”œâ”€â”€ ğŸ¤– agents/                 # Agent implementations
â”‚   â”œâ”€â”€ aggregator/            # Satellite imagery processing
â”‚   â”œâ”€â”€ assessor/              # Impact analysis & heat-maps
â”‚   â”œâ”€â”€ allocator/             # Resource optimization
â”‚   â”œâ”€â”€ comms/                 # Multilingual communications
â”‚   â””â”€â”€ reporter/              # PDF report generation
â”œâ”€â”€ ğŸ”§ common/                 # Shared utilities
â”‚   â”œâ”€â”€ logging.py             # Structured logging
â”‚   â”œâ”€â”€ pubsub_client.py       # Pub/Sub messaging
â”‚   â””â”€â”€ firestore_client.py    # State management
â”œâ”€â”€ ğŸ—ï¸ infra/
â”‚   â””â”€â”€ terraform/             # Infrastructure as code
â”œâ”€â”€ ğŸ“¡ proto/
â”‚   â””â”€â”€ api.proto              # Inter-agent message schema
â”œâ”€â”€ ğŸ§ª scripts/
â”‚   â”œâ”€â”€ bootstrap.sh           # Deployment automation
â”‚   â”œâ”€â”€ load_inventory.py      # Sample data loader
â”‚   â””â”€â”€ publish_mocks.py       # Testing utilities
â””â”€â”€ ğŸ“Š models/
    â””â”€â”€ vision_model/          # Custom damage detection model
```

## ğŸ® Demo Scenarios

### Hurricane Response
```bash
# Simulate Category 3 hurricane with 10-minute progression
python3 scripts/publish_mocks.py \
  --project-id $GOOGLE_CLOUD_PROJECT \
  --scenario hurricane \
  --duration 10
```

### Wildfire Alert
```bash
# Single high-severity wildfire event
python3 scripts/publish_mocks.py \
  --project-id $GOOGLE_CLOUD_PROJECT \
  --single-event \
  --event-type fire \
  --severity 85
```

### Earthquake Response
```bash
# Earthquake scenario with aftershocks
python3 scripts/publish_mocks.py \
  --project-id $GOOGLE_CLOUD_PROJECT \
  --scenario earthquake \
  --duration 15
```

## ğŸ“Š Monitoring & Observability

### Cloud Console Links
- **Agent Logs**: `https://console.cloud.google.com/run?project={PROJECT_ID}`
- **Pub/Sub Topics**: `https://console.cloud.google.com/cloudpubsub/topic/list?project={PROJECT_ID}`
- **BigQuery Data**: `https://console.cloud.google.com/bigquery?project={PROJECT_ID}`
- **Situation Reports**: `https://console.cloud.google.com/storage/browser/{PROJECT_ID}-situation-reports`

### Key Metrics Dashboard

```bash
# Create monitoring dashboard
gcloud monitoring dashboards create --config-from-file=monitoring/dashboard.json
```

### Alert Policies
- Agent error rate > 10/min â†’ PagerDuty
- Resource allocation time > 5 min â†’ Slack
- Critical impact zones detected â†’ SMS to incident commander

## ğŸ”§ Development

### Local Development Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Setup environment
export GOOGLE_CLOUD_PROJECT="your-dev-project"
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account.json"

# Run individual agent locally
cd agents/aggregator
python main.py
```

### Adding New Agent

1. Create agent directory: `agents/new_agent/`
2. Implement `main.py` with agent logic
3. Add to `scripts/bootstrap.sh` deployment
4. Update `proto/api.proto` for new message types
5. Add monitoring and tests

### Testing

```bash
# Unit tests
python -m pytest tests/unit/

# Integration tests
python -m pytest tests/integration/

# End-to-end test
python -m pytest tests/e2e/test_full_scenario.py
```

## ğŸŒ Multi-Language Support

ResilientFlow supports alerts in:
- ğŸ‡ºğŸ‡¸ English (en)
- ğŸ‡ªğŸ‡¸ Spanish (es) 
- ğŸ‡«ğŸ‡· French (fr)

Additional languages can be added via Google Translate API integration.

## ğŸ“± Mobile Integration

### Firebase Cloud Messaging Setup

1. Create Firebase project
2. Download `google-services.json`
3. Configure FCM topics:
   - `resilientflow_en` (English alerts)
   - `resilientflow_es` (Spanish alerts)
   - `resilientflow_fr` (French alerts)

### Sample Mobile App

```javascript
// Subscribe to disaster alerts
messaging.subscribeToTopic('resilientflow_en');

// Handle incoming alerts
messaging.onMessage((payload) => {
  showNotification(payload.notification.title, payload.notification.body);
});
```

## ğŸ”’ Security & Compliance

### Data Privacy
- Only anonymized geo-events stored
- No personal identifiers in disaster data
- GDPR-compliant data retention (30 days)

### Access Control
- Service accounts with least-privilege permissions
- VPC-SC perimeter for sensitive data
- Workload Identity Federation for external APIs

### Compliance
- SOC 2 Type II (Google Cloud)
- ISO 27001 certified infrastructure
- FEMA compliance for CAP XML alerts

## ğŸ’° Cost Optimization

### Resource Scaling
- Cloud Run: Autoscale to 0 when idle
- BigQuery: Query slots auto-allocated
- Pub/Sub: Pay per message

### Estimated Monthly Cost

| Component | Usage | Cost (USD) |
|-----------|-------|------------|
| Cloud Run | 5 agents Ã— 24/7 | $15 |
| BigQuery | 1TB geo data | $50 |
| Pub/Sub | 1M messages | $40 |
| Cloud Storage | 100GB reports | $2 |
| Vertex AI | 10K images | $22 |
| **Total** | | **~$129** |

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Workflow
1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

### Code Standards
- Python: Black formatting, type hints
- Terraform: terraform fmt
- Protobuf: buf linting
- Documentation: Clear docstrings and README updates

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Google Cloud** for serverless infrastructure
- **OR-Tools** for optimization algorithms  
- **ADK Framework** for agent orchestration
- **OpenStreetMap** for geographical data
- **FEMA** for CAP XML standards

## ğŸ“ Support

- ğŸ“§ Email: support@resilientflow.org
- ğŸ’¬ Discord: [ResilientFlow Community](https://discord.gg/resilientflow)
- ğŸ› Issues: [GitHub Issues](https://github.com/your-org/resilientflow/issues)
- ğŸ“– Docs: [docs.resilientflow.org](https://docs.resilientflow.org)

---

**Built with â¤ï¸ for disaster-affected communities worldwide**

*"In the face of disaster, coordination saves lives."* 